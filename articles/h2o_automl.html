<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="lares">
<title>Introduction to AutoML using lares • lares</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.1.3/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.1.3/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.rawgit.com/afeld/bootstrap-toc/v1.0.1/dist/bootstrap-toc.min.js"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Introduction to AutoML using lares">
<meta property="og:description" content="lares">
<meta property="og:image" content="https://laresbernardo.github.io/lares/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--><!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=UA-166493168-2"></script><script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-166493168-2');
</script>
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">lares</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">5.1.5</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/h2o_automl.html">Introduction to AutoML using lares</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/laresbernardo/lares/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">



<script src="h2o_automl_files/accessible-code-block-0.0.1/empty-anchor.js"></script><div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Introduction to AutoML using lares</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/laresbernardo/lares/blob/HEAD/vignettes/h2o_automl.Rmd" class="external-link"><code>vignettes/h2o_automl.Rmd</code></a></small>
      <div class="d-none name"><code>h2o_automl.Rmd</code></div>
    </div>

    
    
<p>The <code>lares</code> package has multiple families of functions to help the analyst or data scientist achieve quality robust analysis without the need of much coding. One of the most complex but valuable functions we have is <code>h2o_automl</code>, which semi-automatically runs the whole pipeline of a Machine Learning model given a dataset and some customizable parameters. <strong>AutoML</strong> enables you to train high-quality models specific to your needs and accelerate the research and development process.</p>
<p><strong>HELP</strong>: Before getting to the code, I recommend checking <code>h2o_automl</code>’s full documentation <a href="https://laresbernardo.github.io/lares/reference/h2o_automl.html">here</a> or within your R session by running <code><a href="../reference/h2o_automl.html">?lares::h2o_automl</a></code>. In it you’ll find a brief description of all the parameters you can set into the function to get exactly what you need and control how it behaves.</p>
<div class="section level2">
<h2 id="pipeline">Pipeline<a class="anchor" aria-label="anchor" href="#pipeline"></a>
</h2>
<p>In short, these are some of the things that happen on its backend:</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/laresbernardo/lares/master/man/figures/automl_map.png" style="width:100.0%" alt=""><p class="caption">Mapping <code>h2o_automl</code></p>
</div>
<ol style="list-style-type: decimal">
<li><p>Input a dataframe <code>df</code> and choose which one is the independent variable (<code>y</code>) you’d like to predict. You may set/change the <code>seed</code> argument to guarantee reproducibility of your results.</p></li>
<li><p>The function decides if it’s a classification (categorical) or regression (continuous) model looking at the independent variable’s (<code>y</code>) class and number of unique values, which can be control with the <code>thresh</code> parameter.</p></li>
<li><p>The dataframe will be split in two: test and train datasets. The proportion of this split can be control with the <code>split</code> argument. This can be replicated with the <code><a href="../reference/msplit.html">msplit()</a></code> function.</p></li>
<li><p>You could also <code>center</code> and <code>scale</code> your numerical values before you continue, use the <code>no_outliers</code> to exclude some outliers, and/or <code>impute</code> missing values with <code>MICE</code>. If it’s a classification model, the function can balance (under-sample) your training data. You can control this behavior with the <code>balance</code> argument. Until here, you can replicate the whole process with the <code><a href="../reference/model_preprocess.html">model_preprocess()</a></code> function.</p></li>
<li><p>Runs <code>h2o::h2o.automl(...)</code> to train multiple models and generate a leaderboard with the top (<code>max_models</code> or <code>max_time</code>) models trained, sorted by their performance. You can also customize some additional arguments such as <code>nfolds</code> for k-fold cross-validations, <code>exclude_algos</code> and <code>include_algos</code> to exclude or include some algorithms, and any other additional argument you wish to pass to the mother function.</p></li>
<li><p>The best model given the default performance metric (which can be changed with <code>stopping_metric</code> parameter) evaluated with cross-validation (customize it with <code>nfolds</code>), will be selected to continue. You can also use the function <code><a href="../reference/h2o_selectmodel.html">h2o_selectmodel()</a></code> to select another model and recalculate/plot everything again using this alternate model.</p></li>
<li><p>Performance metrics and plots will be calculated and rendered given the test predictions and test actual values (which were NOT passed to the models as inputs to be trained with). That way, your model’s performance metrics shouldn’t be biased. You can replicate these calculations with the <code><a href="../reference/model_metrics.html">model_metrics()</a></code> function.</p></li>
<li><p>A list with all the inputs, leaderboard results, best selected model, performance metrics, and plots. You can either (play) see the results on console or export them using the <code><a href="../reference/export_results.html">export_results()</a></code> function.</p></li>
</ol>
</div>
<div class="section level2">
<h2 id="load-the-library">Load the library<a class="anchor" aria-label="anchor" href="#load-the-library"></a>
</h2>
<p>Now, let’s (install and) load the library, the data, and dig in:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("lares")</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/laresbernardo/lares" class="external-link">lares</a></span><span class="op">)</span></span>
<span></span>
<span><span class="co"># The data we'll use is the Titanic dataset</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">dft</span><span class="op">)</span></span>
<span><span class="va">df</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/subset.html" class="external-link">subset</a></span><span class="op">(</span><span class="va">dft</span>, select <span class="op">=</span> <span class="op">-</span><span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">Ticket</span>, <span class="va">PassengerId</span>, <span class="va">Cabin</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><strong>NOTE</strong>: I’ll randomly set some parameters on each example to give visibility on some of the arguments you can set to your models. Be sure to also check all the print, warnings, and messages shown throughout the process as they may have relevant information regarding your inputs and the backend operations.</p>
</div>
<div class="section level2">
<h2 id="modeling-examples">Modeling examples<a class="anchor" aria-label="anchor" href="#modeling-examples"></a>
</h2>
<p>Let’s have a look at three specific examples: <strong>classification models (binary and multiple categories) and a regression model</strong>. Also, let’s see how we can export our models and put them to work on any environment.</p>
<div class="section level3">
<h3 id="classification-binary">Classification: Binary<a class="anchor" aria-label="anchor" href="#classification-binary"></a>
</h3>
<p>Let’s begin with a binary (TRUE/FALSE) model to predict if each passenger <code>Survived</code>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1"></a>r &lt;-<span class="st"> </span><span class="kw">h2o_automl</span>(df, <span class="dt">y =</span> Survived, <span class="dt">max_models =</span> <span class="dv">1</span>, <span class="dt">impute =</span> <span class="ot">FALSE</span>, <span class="dt">target =</span> <span class="st">"TRUE"</span>)</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="co">#&gt; 2022-09-09 23:57:52 | Started process...</span></span>
<span id="cb2-3"><a href="#cb2-3"></a><span class="co">#&gt; Warning in h2o.clusterInfo(): </span></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co">#&gt; Your H2O cluster version is too old (3 months and 14 days)!</span></span>
<span id="cb2-5"><a href="#cb2-5"></a><span class="co">#&gt; Please download and install the latest version from http://h2o.ai/download/</span></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="co">#&gt; - INDEPENDENT VARIABLE: Survived</span></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#&gt; - MODEL TYPE: Classification</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="co">#&gt;  [38;5;246m# A tibble: 2 × 5 [39m</span></span>
<span id="cb2-9"><a href="#cb2-9"></a><span class="co">#&gt;   tag       n     p order  pcum</span></span>
<span id="cb2-10"><a href="#cb2-10"></a><span class="co">#&gt;    [3m [38;5;246m&lt;lgl&gt; [39m [23m  [3m [38;5;246m&lt;int&gt; [39m [23m  [3m [38;5;246m&lt;dbl&gt; [39m [23m  [3m [38;5;246m&lt;int&gt; [39m [23m  [3m [38;5;246m&lt;dbl&gt; [39m [23m</span></span>
<span id="cb2-11"><a href="#cb2-11"></a><span class="co">#&gt;  [38;5;250m1 [39m FALSE   549  61.6     1  61.6</span></span>
<span id="cb2-12"><a href="#cb2-12"></a><span class="co">#&gt;  [38;5;250m2 [39m TRUE    342  38.4     2 100</span></span>
<span id="cb2-13"><a href="#cb2-13"></a><span class="co">#&gt; - MISSINGS: The following variables contain missing observations: Age (19.87%). Consider using the impute parameter.</span></span>
<span id="cb2-14"><a href="#cb2-14"></a><span class="co">#&gt; - CATEGORICALS: There are 3 non-numerical features. Consider using ohse() or equivalent prior to encode categorical variables.</span></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co">#&gt; &gt;&gt;&gt; Splitting data: train = 0.7 &amp; test = 0.3</span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="co">#&gt; train_size  test_size </span></span>
<span id="cb2-17"><a href="#cb2-17"></a><span class="co">#&gt;        623        268</span></span>
<span id="cb2-18"><a href="#cb2-18"></a><span class="co">#&gt; - REPEATED: There were 70 repeated rows which are being suppressed from the train dataset</span></span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="co">#&gt; - ALGORITHMS: excluded 'StackedEnsemble', 'DeepLearning'</span></span>
<span id="cb2-20"><a href="#cb2-20"></a><span class="co">#&gt; - CACHE: Previous models are not being erased. You may use 'start_clean' [clear] or 'project_name' [join]</span></span>
<span id="cb2-21"><a href="#cb2-21"></a><span class="co">#&gt; - UI: You may check results using H2O Flow's interactive platform: http://localhost:54321/flow/index.html</span></span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="co">#&gt; &gt;&gt;&gt; Iterating until 1 models or 600 seconds...</span></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="co">#&gt; </span></span>
<span id="cb2-24"><a href="#cb2-24"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-25"><a href="#cb2-25"></a><span class="st">  </span><span class="er">|</span><span class="st">                                                                      </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%</span>
<span id="cb2-26"><a href="#cb2-26"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-27"><a href="#cb2-27"></a><span class="st">  </span><span class="er">|======================================================================|</span><span class="st"> </span><span class="dv">100</span>%</span>
<span id="cb2-28"><a href="#cb2-28"></a><span class="co">#&gt; - EUREKA: Succesfully generated 1 models</span></span>
<span id="cb2-29"><a href="#cb2-29"></a><span class="co">#&gt;                             model_id       auc   logloss     aucpr</span></span>
<span id="cb2-30"><a href="#cb2-30"></a><span class="co">#&gt; 1 XGBoost_1_AutoML_1_20220909_235753 0.8448546 0.4560409 0.8165146</span></span>
<span id="cb2-31"><a href="#cb2-31"></a><span class="co">#&gt;   mean_per_class_error      rmse       mse</span></span>
<span id="cb2-32"><a href="#cb2-32"></a><span class="co">#&gt; 1            0.2037811 0.3795196 0.1440351</span></span>
<span id="cb2-33"><a href="#cb2-33"></a><span class="co">#&gt; SELECTED MODEL: XGBoost_1_AutoML_1_20220909_235753</span></span>
<span id="cb2-34"><a href="#cb2-34"></a><span class="co">#&gt; - </span><span class="al">NOTE</span><span class="co">: The following variables were the least important: Embarked.C, Parch, SibSp, Embarked.S, Pclass.2</span></span>
<span id="cb2-35"><a href="#cb2-35"></a><span class="co">#&gt; &gt;&gt;&gt; Running predictions for Survived...</span></span>
<span id="cb2-36"><a href="#cb2-36"></a><span class="co">#&gt; </span></span>
<span id="cb2-37"><a href="#cb2-37"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-38"><a href="#cb2-38"></a><span class="st">  </span><span class="er">|</span><span class="st">                                                                      </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%</span>
<span id="cb2-39"><a href="#cb2-39"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-40"><a href="#cb2-40"></a><span class="st">  </span><span class="er">|======================================================================|</span><span class="st"> </span><span class="dv">100</span>%</span>
<span id="cb2-41"><a href="#cb2-41"></a><span class="co">#&gt; </span></span>
<span id="cb2-42"><a href="#cb2-42"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-43"><a href="#cb2-43"></a><span class="st">  </span><span class="er">|</span><span class="st">                                                                      </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%</span>
<span id="cb2-44"><a href="#cb2-44"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb2-45"><a href="#cb2-45"></a><span class="st">  </span><span class="er">|======================================================================|</span><span class="st"> </span><span class="dv">100</span>%</span>
<span id="cb2-46"><a href="#cb2-46"></a><span class="co">#&gt; Target value: TRUE</span></span>
<span id="cb2-47"><a href="#cb2-47"></a><span class="co">#&gt; &gt;&gt;&gt; Generating plots...</span></span>
<span id="cb2-48"><a href="#cb2-48"></a><span class="co">#&gt; Model (1/1): XGBoost_1_AutoML_1_20220909_235753</span></span>
<span id="cb2-49"><a href="#cb2-49"></a><span class="co">#&gt; Independent Variable: Survived</span></span>
<span id="cb2-50"><a href="#cb2-50"></a><span class="co">#&gt; Type: Classification (2 classes)</span></span>
<span id="cb2-51"><a href="#cb2-51"></a><span class="co">#&gt; Algorithm: XGBOOST</span></span>
<span id="cb2-52"><a href="#cb2-52"></a><span class="co">#&gt; Split: 70% training data (of 891 observations)</span></span>
<span id="cb2-53"><a href="#cb2-53"></a><span class="co">#&gt; Seed: 0</span></span>
<span id="cb2-54"><a href="#cb2-54"></a><span class="co">#&gt; </span></span>
<span id="cb2-55"><a href="#cb2-55"></a><span class="co">#&gt; Test metrics:</span></span>
<span id="cb2-56"><a href="#cb2-56"></a><span class="co">#&gt;    AUC = 0.88682</span></span>
<span id="cb2-57"><a href="#cb2-57"></a><span class="co">#&gt;    ACC = 0.16791</span></span>
<span id="cb2-58"><a href="#cb2-58"></a><span class="co">#&gt;    PRC = 0.1369</span></span>
<span id="cb2-59"><a href="#cb2-59"></a><span class="co">#&gt;    TPR = 0.22772</span></span>
<span id="cb2-60"><a href="#cb2-60"></a><span class="co">#&gt;    TNR = 0.13174</span></span>
<span id="cb2-61"><a href="#cb2-61"></a><span class="co">#&gt; </span></span>
<span id="cb2-62"><a href="#cb2-62"></a><span class="co">#&gt; Most important variables:</span></span>
<span id="cb2-63"><a href="#cb2-63"></a><span class="co">#&gt;    Sex.female (35.6%)</span></span>
<span id="cb2-64"><a href="#cb2-64"></a><span class="co">#&gt;    Age (18.6%)</span></span>
<span id="cb2-65"><a href="#cb2-65"></a><span class="co">#&gt;    Fare (18.3%)</span></span>
<span id="cb2-66"><a href="#cb2-66"></a><span class="co">#&gt;    Pclass.3 (12.6%)</span></span>
<span id="cb2-67"><a href="#cb2-67"></a><span class="co">#&gt;    Sex.male (7.7%)</span></span>
<span id="cb2-68"><a href="#cb2-68"></a><span class="co">#&gt; Process duration: 8.34s</span></span></code></pre></div>
<p>Let’s take a look at the plots generated into a single dashboard:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span></code></pre></div>
<p><img src="h2o_automl_files/figure-html/class_2_print-1.png" width="497"></p>
<p>We also have several calculations for our model’s performance that may come useful such as a confusion matrix, gain and lift by percentile, area under the curve (AUC), accuracy (ACC), recall or true positive rate (TPR), cross-validation metrics, exact thresholds to maximize each metric, and others:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">r</span><span class="op">$</span><span class="va">metrics</span></span>
<span><span class="co">#&gt; $dictionary</span></span>
<span><span class="co">#&gt; [1] "AUC: Area Under the Curve"                                                             </span></span>
<span><span class="co">#&gt; [2] "ACC: Accuracy"                                                                         </span></span>
<span><span class="co">#&gt; [3] "PRC: Precision = Positive Predictive Value"                                            </span></span>
<span><span class="co">#&gt; [4] "TPR: Sensitivity = Recall = Hit rate = True Positive Rate"                             </span></span>
<span><span class="co">#&gt; [5] "TNR: Specificity = Selectivity = True Negative Rate"                                   </span></span>
<span><span class="co">#&gt; [6] "Logloss (Error): Logarithmic loss [Neutral classification: 0.69315]"                   </span></span>
<span><span class="co">#&gt; [7] "Gain: When best n deciles selected, what % of the real target observations are picked?"</span></span>
<span><span class="co">#&gt; [8] "Lift: When best n deciles selected, how much better than random is?"                   </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $confusion_matrix</span></span>
<span><span class="co">#&gt;        Pred</span></span>
<span><span class="co">#&gt; Real    FALSE TRUE</span></span>
<span><span class="co">#&gt;   FALSE    22  145</span></span>
<span><span class="co">#&gt;   TRUE     78   23</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $gain_lift</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 10 × 10</span></span></span>
<span><span class="co">#&gt;    percentile value random target total  gain optimal   lift response score</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;fct&gt;</span>      <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;int&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span> <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> 1          TRUE    10.1     27    27  26.7    26.7 165.      26.7  89.3 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> 2          TRUE    20.5     26    28  52.5    54.5 156.      25.7  69.6 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> 3          TRUE    30.2     17    26  69.3    80.2 129.      16.8  58.6 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> 4          TRUE    39.9      9    26  78.2   100    95.9      8.91 48.5 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> 5          TRUE    50        9    27  87.1   100    74.3      8.91 34.2 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> 6          TRUE    60.1      2    27  89.1   100    48.3      1.98 22.0 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> 7          TRUE    69.8      4    26  93.1   100    33.4      3.96 15.4 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> 8          TRUE    79.9      3    27  96.0   100    20.3      2.97 11.6 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> 9          TRUE    89.9      2    27  98.0   100     9.00     1.98  8.54</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> 10         TRUE   100        2    27 100     100     0        1.98  6.11</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $metrics</span></span>
<span><span class="co">#&gt;       AUC     ACC    PRC     TPR     TNR</span></span>
<span><span class="co">#&gt; 1 0.88682 0.16791 0.1369 0.22772 0.13174</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $cv_metrics</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># A tibble: 20 × 8</span></span></span>
<span><span class="co">#&gt;    metric                    mean     sd cv_1_…¹ cv_2_…² cv_3_…³ cv_4_…⁴ cv_5_…⁵</span></span>
<span><span class="co">#&gt;    <span style="color: #949494; font-style: italic;">&lt;chr&gt;</span>                    <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>  <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span>   <span style="color: #949494; font-style: italic;">&lt;dbl&gt;</span></span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 1</span> accuracy                 0.814 0.052<span style="text-decoration: underline;">9</span>   0.816   0.792   0.816   0.895   0.75 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 2</span> auc                      0.851 0.056<span style="text-decoration: underline;">1</span>   0.891   0.804   0.799   0.927   0.832</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 3</span> err                      0.186 0.052<span style="text-decoration: underline;">9</span>   0.184   0.208   0.184   0.105   0.25 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 4</span> err_count               23.2   6.57    23      26      23      13      31    </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 5</span> f0point5                 0.753 0.063<span style="text-decoration: underline;">6</span>   0.714   0.727   0.749   0.864   0.712</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 6</span> f1                       0.762 0.068<span style="text-decoration: underline;">4</span>   0.763   0.717   0.709   0.879   0.744</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 7</span> f2                       0.774 0.087<span style="text-decoration: underline;">8</span>   0.819   0.708   0.673   0.894   0.779</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 8</span> lift_top_group           2.61  0.311    2.91    2.66    2.91    2.38    2.21 </span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;"> 9</span> logloss                  0.456 0.057<span style="text-decoration: underline;">1</span>   0.412   0.497   0.505   0.379   0.487</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">10</span> max_per_class_error      0.252 0.093<span style="text-decoration: underline;">7</span>   0.207   0.298   0.349   0.111   0.294</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">11</span> mcc                      0.611 0.108    0.626   0.553   0.581   0.787   0.508</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">12</span> mean_per_class_accuracy  0.806 0.057<span style="text-decoration: underline;">2</span>   0.827   0.774   0.777   0.896   0.755</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">13</span> mean_per_class_error     0.194 0.057<span style="text-decoration: underline;">2</span>   0.173   0.226   0.223   0.104   0.245</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">14</span> mse                      0.144 0.022<span style="text-decoration: underline;">2</span>   0.130   0.161   0.161   0.112   0.156</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">15</span> pr_auc                   0.822 0.078<span style="text-decoration: underline;">7</span>   0.818   0.784   0.720   0.928   0.861</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">16</span> precision                0.749 0.069<span style="text-decoration: underline;">8</span>   0.685   0.733   0.778   0.855   0.692</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">17</span> r2                       0.387 0.101    0.426   0.315   0.285   0.540   0.369</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">18</span> recall                   0.784 0.106    0.860   0.702   0.651   0.904   0.804</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">19</span> rmse                     0.379 0.029<span style="text-decoration: underline;">9</span>   0.360   0.401   0.402   0.335   0.395</span></span>
<span><span class="co">#&gt; <span style="color: #BCBCBC;">20</span> specificity              0.827 0.080<span style="text-decoration: underline;">2</span>   0.793   0.846   0.902   0.889   0.706</span></span>
<span><span class="co">#&gt; <span style="color: #949494;"># … with abbreviated variable names ¹​cv_1_valid, ²​cv_2_valid, ³​cv_3_valid,</span></span></span>
<span><span class="co">#&gt; <span style="color: #949494;">#   ⁴​cv_4_valid, ⁵​cv_5_valid</span></span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $max_metrics</span></span>
<span><span class="co">#&gt;                         metric  threshold       value idx</span></span>
<span><span class="co">#&gt; 1                       max f1 0.42773205   0.7500000 192</span></span>
<span><span class="co">#&gt; 2                       max f2 0.22019790   0.7974301 271</span></span>
<span><span class="co">#&gt; 3                 max f0point5 0.59904498   0.7770632 137</span></span>
<span><span class="co">#&gt; 4                 max accuracy 0.51057428   0.8089888 164</span></span>
<span><span class="co">#&gt; 5                max precision 0.97219682   1.0000000   0</span></span>
<span><span class="co">#&gt; 6                   max recall 0.04401401   1.0000000 399</span></span>
<span><span class="co">#&gt; 7              max specificity 0.97219682   1.0000000   0</span></span>
<span><span class="co">#&gt; 8             max absolute_mcc 0.42773205   0.5933601 192</span></span>
<span><span class="co">#&gt; 9   max min_per_class_accuracy 0.35598813   0.7696335 216</span></span>
<span><span class="co">#&gt; 10 max mean_per_class_accuracy 0.42773205   0.7962189 192</span></span>
<span><span class="co">#&gt; 11                     max tns 0.97219682 382.0000000   0</span></span>
<span><span class="co">#&gt; 12                     max fns 0.97219682 240.0000000   0</span></span>
<span><span class="co">#&gt; 13                     max fps 0.04549024 382.0000000 398</span></span>
<span><span class="co">#&gt; 14                     max tps 0.04401401 241.0000000 399</span></span>
<span><span class="co">#&gt; 15                     max tnr 0.97219682   1.0000000   0</span></span>
<span><span class="co">#&gt; 16                     max fnr 0.97219682   0.9958506   0</span></span>
<span><span class="co">#&gt; 17                     max fpr 0.04549024   1.0000000 398</span></span>
<span><span class="co">#&gt; 18                     max tpr 0.04401401   1.0000000 399</span></span></code></pre></div>
<p>The same goes for the plots generated for these metrics. We have the gains and response plots on test data-set, confusion matrix, and ROC curves.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">r</span><span class="op">$</span><span class="va">plots</span><span class="op">$</span><span class="va">metrics</span></span>
<span><span class="co">#&gt; $gains</span></span></code></pre></div>
<p><img src="h2o_automl_files/figure-html/class_2_metrics_plots-1.png" width="497"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $response</span></span></code></pre>
<p><img src="h2o_automl_files/figure-html/class_2_metrics_plots-2.png" width="497"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $conf_matrix</span></span></code></pre>
<p><img src="h2o_automl_files/figure-html/class_2_metrics_plots-3.png" width="497"></p>
<pre><code><span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; $ROC</span></span></code></pre>
<p><img src="h2o_automl_files/figure-html/class_2_metrics_plots-4.png" width="497"></p>
<p>For all models, regardless of their type (classification or regression), you can check the importance of each variable as well:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">r</span><span class="op">$</span><span class="va">importance</span><span class="op">)</span></span>
<span><span class="co">#&gt;     variable relative_importance scaled_importance importance</span></span>
<span><span class="co">#&gt; 1 Sex.female           192.18704        1.00000000 0.35582277</span></span>
<span><span class="co">#&gt; 2        Age           100.67931        0.52386109 0.18640170</span></span>
<span><span class="co">#&gt; 3       Fare            98.92374        0.51472636 0.18315136</span></span>
<span><span class="co">#&gt; 4   Pclass.3            67.84911        0.35303684 0.12561854</span></span>
<span><span class="co">#&gt; 5   Sex.male            41.51847        0.21603156 0.07686895</span></span>
<span><span class="co">#&gt; 6   Pclass.1            12.31310        0.06406831 0.02279696</span></span>
<span></span>
<span><span class="va">r</span><span class="op">$</span><span class="va">plots</span><span class="op">$</span><span class="va">importance</span></span></code></pre></div>
<p><img src="h2o_automl_files/figure-html/class_2_importance-1.png" width="497"></p>
</div>
<div class="section level3">
<h3 id="classification-multi-categorical">Classification: Multi-Categorical<a class="anchor" aria-label="anchor" href="#classification-multi-categorical"></a>
</h3>
<p>Now, let’s run a multi-categorical (+2 labels) model to predict <code>Pclass</code> of each passenger:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1"></a>r &lt;-<span class="st"> </span><span class="kw">h2o_automl</span>(df, Pclass, <span class="dt">ignore =</span> <span class="kw">c</span>(<span class="st">"Fare"</span>, <span class="st">"Cabin"</span>), <span class="dt">max_time =</span> <span class="dv">30</span>, <span class="dt">plots =</span> <span class="ot">FALSE</span>)</span>
<span id="cb10-2"><a href="#cb10-2"></a><span class="co">#&gt; 2022-09-09 23:58:05 | Started process...</span></span>
<span id="cb10-3"><a href="#cb10-3"></a><span class="co">#&gt; Warning in h2o.clusterInfo(): </span></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co">#&gt; Your H2O cluster version is too old (3 months and 14 days)!</span></span>
<span id="cb10-5"><a href="#cb10-5"></a><span class="co">#&gt; Please download and install the latest version from http://h2o.ai/download/</span></span>
<span id="cb10-6"><a href="#cb10-6"></a><span class="co">#&gt; - INDEPENDENT VARIABLE: Pclass</span></span>
<span id="cb10-7"><a href="#cb10-7"></a><span class="co">#&gt; - MODEL TYPE: Classification</span></span>
<span id="cb10-8"><a href="#cb10-8"></a><span class="co">#&gt;  [38;5;246m# A tibble: 3 × 5 [39m</span></span>
<span id="cb10-9"><a href="#cb10-9"></a><span class="co">#&gt;   tag       n     p order  pcum</span></span>
<span id="cb10-10"><a href="#cb10-10"></a><span class="co">#&gt;    [3m [38;5;246m&lt;fct&gt; [39m [23m  [3m [38;5;246m&lt;int&gt; [39m [23m  [3m [38;5;246m&lt;dbl&gt; [39m [23m  [3m [38;5;246m&lt;int&gt; [39m [23m  [3m [38;5;246m&lt;dbl&gt; [39m [23m</span></span>
<span id="cb10-11"><a href="#cb10-11"></a><span class="co">#&gt;  [38;5;250m1 [39m n_3     491  55.1     1  55.1</span></span>
<span id="cb10-12"><a href="#cb10-12"></a><span class="co">#&gt;  [38;5;250m2 [39m n_1     216  24.2     2  79.4</span></span>
<span id="cb10-13"><a href="#cb10-13"></a><span class="co">#&gt;  [38;5;250m3 [39m n_2     184  20.6     3 100</span></span>
<span id="cb10-14"><a href="#cb10-14"></a><span class="co">#&gt; - MISSINGS: The following variables contain missing observations: Age (19.87%). Consider using the impute parameter.</span></span>
<span id="cb10-15"><a href="#cb10-15"></a><span class="co">#&gt; - CATEGORICALS: There are 3 non-numerical features. Consider using ohse() or equivalent prior to encode categorical variables.</span></span>
<span id="cb10-16"><a href="#cb10-16"></a><span class="co">#&gt; &gt;&gt;&gt; Splitting data: train = 0.7 &amp; test = 0.3</span></span>
<span id="cb10-17"><a href="#cb10-17"></a><span class="co">#&gt; train_size  test_size </span></span>
<span id="cb10-18"><a href="#cb10-18"></a><span class="co">#&gt;        623        268</span></span>
<span id="cb10-19"><a href="#cb10-19"></a><span class="co">#&gt; - REPEATED: There were 65 repeated rows which are being suppressed from the train dataset</span></span>
<span id="cb10-20"><a href="#cb10-20"></a><span class="co">#&gt; - ALGORITHMS: excluded 'StackedEnsemble', 'DeepLearning'</span></span>
<span id="cb10-21"><a href="#cb10-21"></a><span class="co">#&gt; - CACHE: Previous models are not being erased. You may use 'start_clean' [clear] or 'project_name' [join]</span></span>
<span id="cb10-22"><a href="#cb10-22"></a><span class="co">#&gt; - UI: You may check results using H2O Flow's interactive platform: http://localhost:54321/flow/index.html</span></span>
<span id="cb10-23"><a href="#cb10-23"></a><span class="co">#&gt; &gt;&gt;&gt; Iterating until 3 models or 30 seconds...</span></span>
<span id="cb10-24"><a href="#cb10-24"></a><span class="co">#&gt; - EUREKA: Succesfully generated 3 models</span></span>
<span id="cb10-25"><a href="#cb10-25"></a><span class="co">#&gt;                             model_id mean_per_class_error   logloss      rmse</span></span>
<span id="cb10-26"><a href="#cb10-26"></a><span class="co">#&gt; 1     GLM_1_AutoML_2_20220909_235806            0.4742325 0.8170807 0.5409388</span></span>
<span id="cb10-27"><a href="#cb10-27"></a><span class="co">#&gt; 2 XGBoost_1_AutoML_2_20220909_235806            0.4946035 0.8255072 0.5392879</span></span>
<span id="cb10-28"><a href="#cb10-28"></a><span class="co">#&gt; 3     GBM_1_AutoML_2_20220909_235806            0.5046914 0.8579317 0.5592290</span></span>
<span id="cb10-29"><a href="#cb10-29"></a><span class="co">#&gt;         mse</span></span>
<span id="cb10-30"><a href="#cb10-30"></a><span class="co">#&gt; 1 0.2926147</span></span>
<span id="cb10-31"><a href="#cb10-31"></a><span class="co">#&gt; 2 0.2908315</span></span>
<span id="cb10-32"><a href="#cb10-32"></a><span class="co">#&gt; 3 0.3127371</span></span>
<span id="cb10-33"><a href="#cb10-33"></a><span class="co">#&gt; SELECTED MODEL: GLM_1_AutoML_2_20220909_235806</span></span>
<span id="cb10-34"><a href="#cb10-34"></a><span class="co">#&gt; - </span><span class="al">NOTE</span><span class="co">: The following variables were the least important: Sex.male, Sex.female, Parch</span></span>
<span id="cb10-35"><a href="#cb10-35"></a><span class="co">#&gt; &gt;&gt;&gt; Running predictions for Pclass...</span></span>
<span id="cb10-36"><a href="#cb10-36"></a><span class="co">#&gt; </span></span>
<span id="cb10-37"><a href="#cb10-37"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb10-38"><a href="#cb10-38"></a><span class="st">  </span><span class="er">|</span><span class="st">                                                                      </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%</span>
<span id="cb10-39"><a href="#cb10-39"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb10-40"><a href="#cb10-40"></a><span class="st">  </span><span class="er">|======================================================================|</span><span class="st"> </span><span class="dv">100</span>%</span>
<span id="cb10-41"><a href="#cb10-41"></a><span class="co">#&gt; </span></span>
<span id="cb10-42"><a href="#cb10-42"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb10-43"><a href="#cb10-43"></a><span class="st">  </span><span class="er">|</span><span class="st">                                                                      </span><span class="er">|</span><span class="st">   </span><span class="dv">0</span>%</span>
<span id="cb10-44"><a href="#cb10-44"></a>  <span class="op">|</span><span class="st">                                                                            </span></span>
<span id="cb10-45"><a href="#cb10-45"></a><span class="st">  </span><span class="er">|======================================================================|</span><span class="st"> </span><span class="dv">100</span>%</span>
<span id="cb10-46"><a href="#cb10-46"></a><span class="co">#&gt; Model (1/3): GLM_1_AutoML_2_20220909_235806</span></span>
<span id="cb10-47"><a href="#cb10-47"></a><span class="co">#&gt; Independent Variable: Pclass</span></span>
<span id="cb10-48"><a href="#cb10-48"></a><span class="co">#&gt; Type: Classification (3 classes)</span></span>
<span id="cb10-49"><a href="#cb10-49"></a><span class="co">#&gt; Algorithm: GLM</span></span>
<span id="cb10-50"><a href="#cb10-50"></a><span class="co">#&gt; Split: 70% training data (of 891 observations)</span></span>
<span id="cb10-51"><a href="#cb10-51"></a><span class="co">#&gt; Seed: 0</span></span>
<span id="cb10-52"><a href="#cb10-52"></a><span class="co">#&gt; </span></span>
<span id="cb10-53"><a href="#cb10-53"></a><span class="co">#&gt; Test metrics:</span></span>
<span id="cb10-54"><a href="#cb10-54"></a><span class="co">#&gt;    AUC = 0.76337</span></span>
<span id="cb10-55"><a href="#cb10-55"></a><span class="co">#&gt;    ACC = 0.64179</span></span>
<span id="cb10-56"><a href="#cb10-56"></a><span class="co">#&gt; </span></span>
<span id="cb10-57"><a href="#cb10-57"></a><span class="co">#&gt; Most important variables:</span></span>
<span id="cb10-58"><a href="#cb10-58"></a><span class="co">#&gt;    Embarked.Q (25.3%)</span></span>
<span id="cb10-59"><a href="#cb10-59"></a><span class="co">#&gt;    Embarked.C (13.5%)</span></span>
<span id="cb10-60"><a href="#cb10-60"></a><span class="co">#&gt;    Embarked.S (13.3%)</span></span>
<span id="cb10-61"><a href="#cb10-61"></a><span class="co">#&gt;    Age (11.9%)</span></span>
<span id="cb10-62"><a href="#cb10-62"></a><span class="co">#&gt;    Survived.FALSE (10.6%)</span></span>
<span id="cb10-63"><a href="#cb10-63"></a><span class="co">#&gt; Process duration: 10.8s</span></span></code></pre></div>
<p>Let’s take a look at the plots generated into a single dashboard:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span></code></pre></div>
<p><img src="h2o_automl_files/figure-html/class_3_results-1.png" width="497"></p>
</div>
<div class="section level3">
<h3 id="regression">Regression<a class="anchor" aria-label="anchor" href="#regression"></a>
</h3>
<p>Finally, a regression model with continuous values to predict <code>Fare</code> payed by passenger:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">r</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/h2o_automl.html">h2o_automl</a></span><span class="op">(</span><span class="va">df</span>, y <span class="op">=</span> <span class="st">"Fare"</span>, ignore <span class="op">=</span> <span class="st">"Pclass"</span>, exclude_algos <span class="op">=</span> <span class="cn">NULL</span>, quiet <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; Warning in h2o.clusterInfo(): </span></span>
<span><span class="co">#&gt; Your H2O cluster version is too old (3 months and 14 days)!</span></span>
<span><span class="co">#&gt; Please download and install the latest version from http://h2o.ai/download/</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span>
<span><span class="co">#&gt; Model (1/4): StackedEnsemble_BestOfFamily_1_AutoML_3_20220909_235818</span></span>
<span><span class="co">#&gt; Independent Variable: Fare</span></span>
<span><span class="co">#&gt; Type: Regression</span></span>
<span><span class="co">#&gt; Algorithm: STACKEDENSEMBLE</span></span>
<span><span class="co">#&gt; Split: 70% training data (of 871 observations)</span></span>
<span><span class="co">#&gt; Seed: 0</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Test metrics:</span></span>
<span><span class="co">#&gt;    rmse = 20.055</span></span>
<span><span class="co">#&gt;    mae = 14.026</span></span>
<span><span class="co">#&gt;    mape = 0.069591</span></span>
<span><span class="co">#&gt;    mse = 402.2</span></span>
<span><span class="co">#&gt;    rsq = 0.3691</span></span>
<span><span class="co">#&gt;    rsqa = 0.3667</span></span></code></pre></div>
<p>Let’s take a look at the plots generated into a single dashboard:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">r</span><span class="op">)</span></span></code></pre></div>
<p><img src="h2o_automl_files/figure-html/regression_plots-1.png" width="497"></p>
</div>
</div>
<div class="section level2">
<h2 id="export-models-and-results">Export models and results<a class="anchor" aria-label="anchor" href="#export-models-and-results"></a>
</h2>
<p>Once you have you model trained and picked, you can export the model and it’s results, so you can put it to work in a production environment (doesn’t have to be R). There is a function that does all that for you: <code><a href="../reference/export_results.html">export_results()</a></code>. Simply pass your <code>h2o_automl</code> list object into this function and that’s it! You can select which formats will be exported using the <code>which</code> argument. Currently we support: <code>txt</code>, <code>csv</code>, <code>rds</code>, <code>binary</code>, <code>mojo</code> [best format for production], and <code>plots</code>. There are also 2 quick options (<code>dev</code> and <code>production</code>) to export some or all the files. Lastly, you can set a custom <code>subdir</code> to gather everything into a new sub-directory; I’d recommend using the model’s name or any other convention that helps you know which one’s which.</p>
</div>
<div class="section level2">
<h2 id="import-and-use-your-models">Import and use your models<a class="anchor" aria-label="anchor" href="#import-and-use-your-models"></a>
</h2>
<p>If you’d like to re-use your exported models to predict new datasets, you have several options:</p>
<ul>
<li>
<code><a href="../reference/h2o_predict_MOJO.html">h2o_predict_MOJO()</a></code> <em>[recommended]</em>: This function lets the user predict using <code>h2o</code>’s <code>.zip</code> file containing the MOJO files. These files are also the ones used when putting the model into production on any other environment. Also, MOJO let’s you change <code>h2o</code>’s versions without issues</li>
<li>
<code><a href="../reference/h2o_predict_binary.html">h2o_predict_binary()</a></code>: This function lets the user predict using the h2o binary file. The <code>h2o</code> version/build must match for it to work.</li>
<li>
<code><a href="../reference/h2o_predict_model.html">h2o_predict_model()</a></code>: This function lets the user run predictions from a <code>H2O Model Object</code> same as you’d use the <code>predict</code> base function. Will probably only work in your current session as you must have the actual trained object to use it.</li>
</ul>
</div>
<div class="section level2">
<h2 id="addittional-posts">Addittional Posts<a class="anchor" aria-label="anchor" href="#addittional-posts"></a>
</h2>
<ul>
<li>DataScience+: <a href="https://datascienceplus.com/machine-learning-results-one-plot-to-rule-them-all/" class="external-link">Visualizations for Classification Models Results</a>
</li>
<li>DataScience+: <a href="https://datascienceplus.com/machine-learning-results-in-r-one-plot-to-rule-them-all-part-2-regression-models/" class="external-link">Visualizations for Regression Models Results</a>
</li>
</ul>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Bernardo Lares.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
